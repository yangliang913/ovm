#
# stackone - Pylons development environment configuration
#
# The %(here)s variable will be replaced with the parent directory of this file
#
# This file is for deployment specific config options -- other configuration
# that is always required for the app is done in the config directory, 
# and generally should not be modified by end users. 

[DEFAULT]
debug = false
# Uncomment and replace with the address which should receive any error reports
#email_to = you@yourdomain.com
smtp_server = localhost
error_email_from = paste@localhost
email_from = admin@yourdomain.com
default_public_interface = eth1
[server:main]
use = egg:Paste#http
host = 0.0.0.0
port = 8888

[app:main]
use = egg:stackone
full_stack = true
#lang = ru
cache_dir = %(here)s/data
server_protocol=http
beaker.session.key = stackone_cloud2
beaker.session.secret = somesecret_ee

dwm_migration_instructions_limit = 5
dwm_variance_fetch_interval = 30

#in seconds
node_ports_cache_clear_time = 30

default_store_location = /var/cache/stackone/image_store
common_dir = common
key_pair_abs_path=%(here)s/stackone/public/javascript/cloud/key_pairs/
key_pair_rel_path=/javascript/cloud/key_pairs/
image_store=%(here)s/image_store/
storage_script=%(here)s/storage/scripts
backup_script=%(here)s/default/backup/scripts
restore_script=%(here)s/default/restore/scripts
backup_custom_script=%(here)s/custom/backup/scripts
restore_custom_script=%(here)s/custom/restore/scripts
nw_script=%(here)s/nw/scripts
common_script=%(here)s/common/scripts
ping_script=ping_node
custom_fencing_scripts=%(here)s/custom/fencing/
check_updates_on_startup = True
paramiko_log_file = paramiko.log
gnome_vfs_enabled = False
html_browser = /usr/bin/yelp
log_file = stackone.log
enable_log = True
enable_paramiko_log = False
http_proxy =
default_ssh_port = 22
default_computed_options = ['arch', 'arch_libdir', 'device_model']
use_3_0_api = True
appliance_store = %(here)s/cache/stackone/appliance_store
snapshots_dir = /var/cache/stackone/snapshots
updates_file = %(here)s/cache/stackone/updates.xml
user_config = %(here)s/user_config
exec_path = $PATH:/usr/sbin/
stackone_cache_dir = /var/cache/stackone
log_dir = /var/log/stackone
snapshot_file_ext = .snapshot.xm
snapshot_file_size = 2G
vm_disk_types=['file','tap:aio','tap:qcow','tap:vmdk']
CONFIG_DIRECTORIES=/var/lib/xen;/var/cache/stackone/vm_configs;/etc/xen
VM_CONF_DIR=/var/cache/stackone/vm_configs
#This option allows you to create/edit/delete new privileges, define which operation groups and operations are part of it.
ADVANCED_PRIVILEGES=False
#This option allows setting permissions at individual Servers and Virtual Machine level. 
#When in this mode, the privileges from container to the contained entities will NOT propagate automatically. 
#When a new entity is added, all users having current role would have appropriate privileges on the newly created entity.
GRANULAR_USER_MODEL=False
PROPOGATE_PRIVILEGES_USING_PARENT=False
NODE_LIST_LIMIT=50
CUSTOM_SEARCH_LIMIT=200
BACKUP_SEARCH_LIMIT=200
RESTORE_SEARCH_LIMIT=200
CONCURRENT_PROVISION_COUNT=3

#in seconds
bash_default_timeout = 60

#in minutes
RECOVER_TIME = 1440

#in seconds
server_shutdown_time = 180
ping_timeout = 5
max_ping_servers=10
max_ping_workers=5
completion_time=2

max_worker_wait_time=300
max_node_avail_wait_time=45
max_vm_avail_wait_time=60
max_node_metrics_wait_time=90

#### CLOUD CONFIGURATIONS START ####
fw_namespace=False

max_ping_accounts_cloud=10
max_ping_workers_cloud=5

#In Seconds
cloud_watch_period = 60
#In Hours
cloud_watch_start = 10

#Enable/Disable account while editing CP
cms_cp_account = false
nw_service_host = 
nw_service_root_password = 
nw_service_ssh_port = 22
cidr_format = /24
cms_public_interface = eth0
boto_delay_request_time = 1
#### CLOUD CONFIGURATIONS END ####


temp_path = /var/cache/stackone/tmp
custom_path = /var/cache/stackone/custom
script_path_backup = /var/cache/stackone/default/backup
custom_script_path_backup = /var/cache/stackone/custom/backup
script_path_restore = /var/cache/stackone/default/restore
custom_script_path_restore = /var/cache/stackone/custom/restore
local_path_restore = /var/cache/stackone/tmp/restore

vnc_host=localhost
vnc_port=6900:6999
vnc_user=root
vnc_password=

ssh_forwarder = localhost
ssh_forwarder_port_range = 6900:6999
ssh_forwarder_user = 
ssh_forwarder_password=
# Set True or False
ssh_forwarder_use_keys=False
ssh_forwarder_tunnel_setup = False

vnc_applet_param_height=0
vnc_applet_param_width=0
vnc_applet_param_new_window=Yes
vnc_applet_param_show_controls=Yes
vnc_applet_param_encoding=Hextile
vnc_applet_param_restricted_colors=No
vnc_applet_param_offer_relogin=No

# vnc_log_level value from 0 to 4
vnc_log_level=3
ssh_log_level=3

ssh_file=~/.ssh/cms_id_rsa
license_file=%(here)s/license.txt
deployment_file=%(here)s/deployment_info.txt

ha_wait_for_node_up=False

server_boot_time=120
ping_interval=3
#we have increased start_time to get the VM running after Backup is completed.
start_time=90
view_console_time=5
shutdown_time=60
pause_time=10
#we have increased unpause_time because we were getting time out error while Resuming VM.
unpause_time=60
reboot_time=160
kill_time=10
migrate_time=600
TASKPANEREFRESH=5
PAGEREFRESHINTERVAL=5
UPDATE_DISK_SIZE_INTERVAL=60
backup_time=7200
backup_timeout=7200
restore_timeout=7200
template_timeout=900
default_timeout=900
larger_timeout=900
bridge_prefix=br

NOTIFICATION_COUNT=500
TASK_PURGE_COUNT=5000

MAX_CACHE_SIZE=200
#in minutes
CACHE_TIME=5
SPECIAL_PLATFORMS=['vmw','vcenter']

# enable stacktraces without CMS auth
# enable only for debugging
enable_stack_trace_url=True
enable_used_ports_url=True
enable_fw_stack_trace_url=True

#LDAP details
ldap_trace_level = 0
ldap_network_timeout = 60
ldap_tls_cacertfile = /etc/ssl/certs/cacert.pem
ldap_start_tls = 1
ldap_enabled = False
ldap_host = 127.0.0.1
ldap_port = 389
ldap_basedn = dc=localhost,dc=localdomain
user_key = uid
group_key = group-id
email_key = email
ldap_user_search = ou=Users
ldap_group_search = ou=Groups
ldap_group_objectclass = groupOfNames

#remote system connection commands

vnc=vncviewer $IP:$PORT
tight_vnc=vncviewer $IP:$PORT
vmware-vmrc = vmware-vmrc -h $IP:$PORT -p $TICKET -M $VM_ID

remote_desktop=mstsc /v: $IP /w:640 /h:480
ssh=xterm -hold -e ssh -i $KEYPAIR $USER@$IP
rdesktop=rdesktop -u $USER $IP
putty=putty -i $KEYPAIR $USER@$IP

ssh_cmd  =  xterm -hold -e ssh -p $PORT -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no $USER@$IP
putty_cmd = putty -P $PORT $USER@$IP

dwm_ps_migrate_down_vms = 0

#This is where the services related parameters will go
services.execution.num_threads = 30
services.core.max_wait = 2
services.task.max_sleep = 20

#Reserve Private IPs
private_ip_bottom_reserve = 10
private_ip_top_reserve = 2



# If you'd like to fine-tune the individual locations of the cache data dirs
# for the Cache data, or the Session saves, un-comment the desired settings
# here:
#beaker.cache.data_dir = %(here)s/data/cache
#beaker.session.data_dir = %(here)s/data/sessions

# pick the form for your database
# %(here) may include a ':' character on Windows environments; this can
# invalidate the URI when specifying a SQLite db via path name
# sqlalchemy.url=postgres://username:password@hostname:port/databasename 
sqlalchemy.url=mysql://root:stackone@localhost:3306/stackone_cloud?charset=utf8
#sqlalchemy.url=oracle://username:password@localhost:1521/xe


# If you have sqlite, here's a simple default to get you started
# in development

#sqlalchemy.url = sqlite:///%(here)s/devdata.db
#echo shouldn't be used together with the logging module.
sqlalchemy.echo = false
sqlalchemy.echo_pool = false
sqlalchemy.pool_recycle = 3600
sqlalchemy.pool_size = 10
sqlalchemy.max_overflow = 30

# if you are using Mako and want to be able to reload
# the mako template from disk during the development phase
# you should say 'true' here
# This option is only used for mako templating engine
# WARNING: if you want to deploy your application using a zipped egg
# (ie: if your application's setup.py defines zip-safe=True, then you
# MUST put "false" for the production environment because there will
# be no disk and real files to compare time with.
# On the contrary if your application defines zip-safe=False and is
# deployed in an unzipped manner, then you can leave this option to true
templating.mako.reloadfromdisk = true

# The values given here are in days
purge_hr_data = 60
purge_day_data = 365
purge_week_data = 365
purge_month_data = 365
purge_raw_data = 31
task_results_purge_interval=180
repeating_tasks_purge_interval=15
TaskPaneLimit=7
#no:of rows in notifications grid
notifications_row_limit=200
#no:of rows in task panel
task_panel_row_limit=200


# the compiled template dir is a directory that must be readable by your
# webserver. It will be used to store the resulting templates once compiled
# by the TemplateLookup system.
# During development you generally don't need this option since paste's HTTP
# server will have access to you development directories, but in production
# you'll most certainly want to have apache or nginx to write in a directory
# that does not contain any source code in any form for obvious security reasons.
#
#templating.mako.compiled_templates_dir = /some/dir/where/webserver/has/access

# WARNING: *THE LINE BELOW MUST BE UNCOMMENTED ON A PRODUCTION ENVIRONMENT*
# Debug mode will enable the interactive debugging tool, allowing ANYONE to
# execute malicious code after an exception is raised.
set debug = false

# Logging configuration
# Add additional loggers, handlers, formatters here
# Uses python's logging config file format
# http://docs.python.org/lib/logging-config-fileformat.html

[loggers]
keys = root, stackone, sqlalchemy, auth, tgi18n, HA, AVAIL_TIMING, STORAGE_TIMING, METRICS_TIMING, WORKER

[handlers]
keys = console, rotating, paster

[formatters]
keys = generic, stackone

# If you create additional loggers, add them as a key to [loggers]
[logger_root]
level = WARN
#handlers = console
handlers = paster
formatter = generic

[logger_tgi18n]
level = WARN
handlers = rotating
qualname = tg.i18n

[logger_stackone]
level = DEBUG
handlers = rotating
qualname = stackone

[logger_HA]
level = INFO
handlers = rotating
qualname = HA

[logger_STORAGE_TIMING]
level = WARN
handlers = rotating
qualname = STORAGE_TIMING

[logger_AVAIL_TIMING]
level = WARN
handlers = rotating
qualname = AVAIL_TIMING

[logger_METRICS_TIMING]
level = WARN
handlers = rotating
qualname = METRICS_TIMING

[logger_WORKER]
level = WARN
handlers = rotating
qualname = WORKER

[logger_sqlalchemy]
level = WARN
handlers = rotating
qualname = sqlalchemy.engine
# "level = INFO" logs SQL queries.
# "level = DEBUG" logs SQL queries and results.
# "level = WARN" logs neither.  (Recommended for production systems.)


# A logger for authentication, identification and authorization -- this is
# repoze.who and repoze.what:
[logger_auth]
level = WARN
handlers = rotating
qualname = auth

# If you create additional handlers, add them as a key to [handlers]
[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

# Rotating file handler that creates a log file named stackone.log, backs up to 5 
[handler_rotating]
class = handlers.RotatingFileHandler
args = ('stackone.log','a', 1000000, 5)
#level = DEBUG
formatter = stackone

[handler_paster]
class = handlers.RotatingFileHandler
args = ('paster_console.log', 'a', 1000000, 5)
level = NOTSET
formatter = generic

# If you create additional formatters, add them as a key to [formatters]
[formatter_generic]
format = %(asctime)s,%(msecs)03d %(levelname)-5.5s [%(name)s] [%(filename)s]:%(lineno)d %(message)s
datefmt = %Y-%m-%d %H:%M:%S

[formatter_stackone]
format = %(asctime)s,%(msecs)03d %(levelname)-5.5s [%(name)s] [%(filename)s]:%(lineno)d %(message)s
datefmt = %Y-%m-%d %H:%M:%S

